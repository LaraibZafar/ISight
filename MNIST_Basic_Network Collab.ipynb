{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "MNIST Basic Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LkGkHTcwcZI"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import cv2\n",
        "import time\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmaS34MpwcZP"
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              #transforms.Lambda(lambda x: x.repeat(3, 1, 1) ),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainSet = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testSet = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=64, shuffle=True)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHm1P_JWwcZP"
      },
      "source": [
        "# Use GPU if it's available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTmPkOFbwcZQ",
        "outputId": "c512ee06-ea39-471d-dee7-f6ad5ce195ad"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10),\n",
        "    nn.LogSoftmax(dim=1))\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "epochs = 30\n",
        "model.to(device);\n",
        "#log softmax => more efficient than normal softmax\n",
        "\n",
        "trainLosses, testLosses = [], []\n",
        "for e in range(epochs):\n",
        "    runningLoss = 0\n",
        "    for images, labels in trainLoader:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        modelLogOutput = model(images)\n",
        "        loss = criterion(modelLogOutput, labels)\n",
        "        #back propogation compute gradient of each parameter using the loss\n",
        "        loss.backward()\n",
        "        #Gradient Descent optimizes the parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        runningLoss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        testLoss = 0\n",
        "        accuracy = 0\n",
        "        evaluationStart = time.time()\n",
        "        \n",
        "        # Turn off gradients for validation, reduces memory usage, and easier computations\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for images, labels in testLoader:\n",
        "                images = images.view(images.shape[0], -1)\n",
        "                modelLogOutput = model(images)\n",
        "                testLoss += criterion(modelLogOutput, labels)\n",
        "                \n",
        "                #Converting the log output to a probility\n",
        "                outputProbability = torch.exp(modelLogOutput)\n",
        "                \n",
        "                topProbability, predictedClass = outputProbability.topk(1, dim=1)\n",
        "                predictedClass = torch.squeeze(predictedClass)\n",
        "                equals = (predictedClass == labels)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "        \n",
        "        evaluationEnd = time.time()\n",
        "        model.train()\n",
        "        \n",
        "        trainLosses.append(runningLoss/len(trainLoader))\n",
        "        testLosses.append(testLoss/len(testLoader))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(trainLosses[-1]),\n",
        "              \"Test Loss: {:.3f}.. \".format(testLosses[-1]),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testLoader)),\n",
        "              \"Evaluation Time: {:.3f}\".format((evaluationEnd-evaluationStart)),\n",
        "              \"Evaluation Time per Image: {:.3f}\".format((evaluationEnd-evaluationStart)/len(testLoader)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/30..  Training Loss: 1.832..  Test Loss: 1.155..  Test Accuracy: 0.750 Evaluation Time: 1.764 Evaluation Time per Image: 0.011\n",
            "Epoch: 2/30..  Training Loss: 0.806..  Test Loss: 0.577..  Test Accuracy: 0.849 Evaluation Time: 1.799 Evaluation Time per Image: 0.011\n",
            "Epoch: 3/30..  Training Loss: 0.512..  Test Loss: 0.435..  Test Accuracy: 0.883 Evaluation Time: 1.783 Evaluation Time per Image: 0.011\n",
            "Epoch: 4/30..  Training Loss: 0.420..  Test Loss: 0.382..  Test Accuracy: 0.893 Evaluation Time: 1.899 Evaluation Time per Image: 0.012\n",
            "Epoch: 5/30..  Training Loss: 0.378..  Test Loss: 0.351..  Test Accuracy: 0.901 Evaluation Time: 1.778 Evaluation Time per Image: 0.011\n",
            "Epoch: 6/30..  Training Loss: 0.353..  Test Loss: 0.331..  Test Accuracy: 0.907 Evaluation Time: 1.789 Evaluation Time per Image: 0.011\n",
            "Epoch: 7/30..  Training Loss: 0.335..  Test Loss: 0.321..  Test Accuracy: 0.906 Evaluation Time: 1.741 Evaluation Time per Image: 0.011\n",
            "Epoch: 8/30..  Training Loss: 0.322..  Test Loss: 0.304..  Test Accuracy: 0.914 Evaluation Time: 1.906 Evaluation Time per Image: 0.012\n",
            "Epoch: 9/30..  Training Loss: 0.310..  Test Loss: 0.297..  Test Accuracy: 0.915 Evaluation Time: 1.788 Evaluation Time per Image: 0.011\n",
            "Epoch: 10/30..  Training Loss: 0.302..  Test Loss: 0.285..  Test Accuracy: 0.918 Evaluation Time: 1.958 Evaluation Time per Image: 0.012\n",
            "Epoch: 11/30..  Training Loss: 0.293..  Test Loss: 0.279..  Test Accuracy: 0.922 Evaluation Time: 1.753 Evaluation Time per Image: 0.011\n",
            "Epoch: 12/30..  Training Loss: 0.284..  Test Loss: 0.274..  Test Accuracy: 0.922 Evaluation Time: 1.854 Evaluation Time per Image: 0.012\n",
            "Epoch: 13/30..  Training Loss: 0.277..  Test Loss: 0.264..  Test Accuracy: 0.925 Evaluation Time: 1.925 Evaluation Time per Image: 0.012\n",
            "Epoch: 14/30..  Training Loss: 0.270..  Test Loss: 0.259..  Test Accuracy: 0.926 Evaluation Time: 1.777 Evaluation Time per Image: 0.011\n",
            "Epoch: 15/30..  Training Loss: 0.263..  Test Loss: 0.254..  Test Accuracy: 0.927 Evaluation Time: 1.930 Evaluation Time per Image: 0.012\n",
            "Epoch: 16/30..  Training Loss: 0.256..  Test Loss: 0.247..  Test Accuracy: 0.930 Evaluation Time: 1.808 Evaluation Time per Image: 0.012\n",
            "Epoch: 17/30..  Training Loss: 0.250..  Test Loss: 0.244..  Test Accuracy: 0.932 Evaluation Time: 1.833 Evaluation Time per Image: 0.012\n",
            "Epoch: 18/30..  Training Loss: 0.243..  Test Loss: 0.236..  Test Accuracy: 0.934 Evaluation Time: 1.921 Evaluation Time per Image: 0.012\n",
            "Epoch: 19/30..  Training Loss: 0.237..  Test Loss: 0.230..  Test Accuracy: 0.934 Evaluation Time: 2.131 Evaluation Time per Image: 0.014\n",
            "Epoch: 20/30..  Training Loss: 0.231..  Test Loss: 0.227..  Test Accuracy: 0.934 Evaluation Time: 1.831 Evaluation Time per Image: 0.012\n",
            "Epoch: 21/30..  Training Loss: 0.225..  Test Loss: 0.217..  Test Accuracy: 0.938 Evaluation Time: 1.748 Evaluation Time per Image: 0.011\n",
            "Epoch: 22/30..  Training Loss: 0.219..  Test Loss: 0.217..  Test Accuracy: 0.937 Evaluation Time: 1.988 Evaluation Time per Image: 0.013\n",
            "Epoch: 23/30..  Training Loss: 0.213..  Test Loss: 0.209..  Test Accuracy: 0.939 Evaluation Time: 1.778 Evaluation Time per Image: 0.011\n",
            "Epoch: 24/30..  Training Loss: 0.208..  Test Loss: 0.206..  Test Accuracy: 0.939 Evaluation Time: 1.916 Evaluation Time per Image: 0.012\n",
            "Epoch: 25/30..  Training Loss: 0.202..  Test Loss: 0.202..  Test Accuracy: 0.942 Evaluation Time: 1.760 Evaluation Time per Image: 0.011\n",
            "Epoch: 26/30..  Training Loss: 0.197..  Test Loss: 0.194..  Test Accuracy: 0.944 Evaluation Time: 1.835 Evaluation Time per Image: 0.012\n",
            "Epoch: 27/30..  Training Loss: 0.192..  Test Loss: 0.193..  Test Accuracy: 0.943 Evaluation Time: 1.964 Evaluation Time per Image: 0.013\n",
            "Epoch: 28/30..  Training Loss: 0.187..  Test Loss: 0.186..  Test Accuracy: 0.946 Evaluation Time: 1.954 Evaluation Time per Image: 0.012\n",
            "Epoch: 29/30..  Training Loss: 0.182..  Test Loss: 0.180..  Test Accuracy: 0.946 Evaluation Time: 1.797 Evaluation Time per Image: 0.011\n",
            "Epoch: 30/30..  Training Loss: 0.178..  Test Loss: 0.178..  Test Accuracy: 0.948 Evaluation Time: 1.805 Evaluation Time per Image: 0.011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zu4qNCxwcZQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGe8r2LwwcZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCEK0v-5wcZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9ETeiogwcZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DICGMqRCwcZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}